{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "aca anotar lo q se quiere probar\n",
    "\n",
    "recordar utilizar metricas de comparaci√≥n\n",
    "\n",
    "https://huggingface.co/julien-c/distilbert-feature-extraction\n",
    "\n",
    "CountVectorizer, TFIDF, LSA, LDA, SBERT, spaCy\n",
    "\n",
    "ideas:\n",
    "    (1,2) ngrams of Qpos + Apos   \n",
    "    (1,2) ngrams of Qlemmas\n",
    "    (1,2) ngrams of Alemmas\n",
    "    (1,2) ngrams of AQAQlemmas\n",
    "\n",
    "\n",
    "ya tengo el codigo para agregar features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from TCA import *\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"db/features.csv\", index_col=0)\n",
    "df = df.set_index(\"id\")\n",
    "\n",
    "test_df = pd.read_csv(\"db/test_db.csv\", index_col=0)\n",
    "true_df = test_df[test_df[\"2\"]]\n",
    "false_df = test_df[test_df[\"2\"] == False]\n",
    "\n",
    "n_clusters = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorial Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<98182x704 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 338111 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def cv_ngrams(docs, range=(2,3), min_df=20):\n",
    "    \n",
    "    #2 y 3 ngrams, minimo 20 (no se como elegir le numero correcto)\n",
    "    cv = CountVectorizer(min_df=min_df, ngram_range=range)\n",
    "\n",
    "    \n",
    "    #Create, Normalize and Reduce \n",
    "    vspace = cv.fit_transform(docs)\n",
    "    vspace = normalize(vspace, axis=1, norm=\"max\")\n",
    "    vspace = VarianceThreshold(threshold=1e-3).fit_transform(vspace)\n",
    "\n",
    "    return vspace\n",
    "\n",
    "vs = cv_ngrams(df[\"Q\"])\n",
    "vs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primer cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmc = KMeans(n_clusters=n_clusters, random_state=0)\n",
    "kmc.fit(X=vs)\n",
    "df[\"label1\"] = kmc.labels_\n",
    "\n",
    "#vemos los primeros clusters, al ser con ngrams  la forma en la que comienza la pregunta tiene mucho peso\n",
    "def print_kmc_clus(n=5):\n",
    "    import random\n",
    "    q_clus = [[] for i in range(n_clusters)]\n",
    "\n",
    "    for sentence_id, cluster_id in enumerate(kmc.labels_):\n",
    "        q_clus[cluster_id].append(df.iloc[sentence_id].Q)\n",
    "\n",
    "    for i, cluster in enumerate(q_clus):\n",
    "        print(\"Cluster \", i+1)\n",
    "        for tw in random.sample(cluster, n):\n",
    "            print(tw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprobando similaridad al dataset de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.45155555555555554, 0.8575485754857548)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Compara la cantidad de aciertos con los df de test\n",
    "def check_results():\n",
    "\n",
    "    n = len(true_df)\n",
    "    m = len(false_df)\n",
    "    same_c = 0\n",
    "    for i in range(n):\n",
    "        if int(df.loc[true_df.iloc[i][0]].label1) ==  int(df.loc[true_df.iloc[i][1]].label1):\n",
    "            same_c += 1\n",
    "    \n",
    "    diff_c = 0\n",
    "    for i in range(m):\n",
    "        if int(df.loc[false_df.iloc[i][0]].label1) !=  int(df.loc[false_df.iloc[i][1]].label1):\n",
    "            diff_c += 1\n",
    "        \n",
    "    return same_c/n, diff_c/m\n",
    "        \n",
    "check_results()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#continuo viendo que funciona\n",
    "\n",
    "#embeddings preentrenados\n",
    "# import gensim.downloader\n",
    "\n",
    "# #word2vec-google-news-300\n",
    "# w2v = gensim.downloader.load('glove-twitter-25')\n",
    "# w2v[\"mauro\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
